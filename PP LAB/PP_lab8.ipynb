{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PP lab8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFUXDyTdI8xZ"
      },
      "source": [
        "#Name: Ankita Ghosh\n",
        "#Reg number: 180905354\n",
        "#Sec:A Roll number:41"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHVJX3AfJBn5"
      },
      "source": [
        "Colab Link: https://colab.research.google.com/drive/1TiW9hfEKNGQihyuWlQmin9fd-_0cBurD?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbPMx-7lDIDY"
      },
      "source": [
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVB6aHkAJVGk"
      },
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmTDjVwQJV-X"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fceGVm6wJZG7"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Iy9skZJZbC"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmXqXyB3Jmg7"
      },
      "source": [
        "##26th May: 1D convolution \n",
        "#####Write a program in CUDA which performs convolution operation on one dimensional input array N of size width using a mask array M of size mask_width to produce the resultant one dimensional array P of size width. Find the time taken by the kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4VUe437KPU8",
        "outputId": "a34c48e5-51bb-491f-b4da-911168d89498"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "#include\"cuda_runtime.h\"\n",
        "#include\"device_launch_parameters.h\"\n",
        "\n",
        "__global__ void conv1D(int *N,int *M,int *P,int Mask_width,int Width)\n",
        "{\n",
        "  int i=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  int p=0;\n",
        "  int NStartPoint=i-(Mask_width/2); \n",
        "  for(int j=0;j<Mask_width;j++)\n",
        "  {\n",
        "    if(NStartPoint+j>=0 && NStartPoint+j<Width)\n",
        "    {\n",
        "      p+=N[NStartPoint+j]*M[j];\n",
        "    }\n",
        "  }\n",
        "  P[i]=p;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int Width=10;\n",
        "    int Mask_width=3;\n",
        "\n",
        "    int N[]={0,1,2,3,4,5,6,7,8,9};\n",
        "    printf(\"\\n\\nInput array:\\n\");\n",
        "    for(int i=0;i<Width;i++)\n",
        "    {\n",
        "        printf(\"%d  \",N[i]);\n",
        "    }\n",
        "    int M[]={1,2,1};\n",
        "    printf(\"\\n\\nMask array:\\n\");\n",
        "    for(int i=0;i<Mask_width;i++)\n",
        "    {\n",
        "        printf(\"%d  \",M[i]);\n",
        "    }\n",
        "    \n",
        "    int P[Width];\n",
        "    int size=Width*sizeof(int);\n",
        "    int *d_N,*d_M,*d_P;\n",
        "    cudaEvent_t begin,end;\n",
        "\n",
        "    cudaMalloc((void**)&d_N,size);\n",
        "\t  cudaMalloc((void**)&d_M,Mask_width*sizeof(int));\n",
        "\t  cudaMalloc((void**)&d_P,size);\n",
        "\n",
        "\t  cudaMemcpy(d_N,N,size,cudaMemcpyHostToDevice);\n",
        "\t  cudaMemcpy(d_M,M,Mask_width*sizeof(int),cudaMemcpyHostToDevice);\n",
        "    cudaEventCreate(&begin);\n",
        "    cudaEventCreate(&end);\n",
        "    cudaEventRecord(begin,0);\n",
        "\n",
        "    conv1D<<<1,Width>>>(d_N,d_M,d_P,Mask_width,Width);\n",
        "    cudaEventRecord(end,0);\n",
        "    cudaEventSynchronize(end);\n",
        "    float timeTaken;\n",
        "    cudaEventElapsedTime(&timeTaken,begin,end);\n",
        "\n",
        "    cudaMemcpy(P,d_P,size,cudaMemcpyDeviceToHost);\n",
        "    printf(\"\\n\\nOutput array:\\n\");\n",
        "    for(int i=0;i<Width;i++)\n",
        "    {\n",
        "        printf(\"%d  \",P[i]);\n",
        "    }\n",
        "    printf(\"\\n\\nTime taken by the kernel:\\n%f\",timeTaken);\n",
        "\n",
        "    cudaFree(d_N);\n",
        "\t  cudaFree(d_M);\n",
        "\t  cudaFree(d_P);\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Input array:\n",
            "0  1  2  3  4  5  6  7  8  9  \n",
            "\n",
            "Mask array:\n",
            "1  2  1  \n",
            "\n",
            "Output array:\n",
            "1  4  8  12  16  20  24  28  32  26  \n",
            "\n",
            "Time taken by the kernel:\n",
            "0.019456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMNDa1JtP-GI"
      },
      "source": [
        "#Question 1\n",
        "#####Write a CUDA program to perform convolution operation on one dimensional input array N of size width using a mask array M of size mask_width to produce the resultant one dimensional array P of size width using constant Memory for Mask array.  Add another kernel function to the same program to perform 1D convolution using shared memory. Find and display the time taken by both the kernels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVKXeOM-WKmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785dfed2-c799-454b-e6d8-94fa4a337e55"
      },
      "source": [
        " %%cu\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "#include\"cuda_runtime.h\"\n",
        "#include\"device_launch_parameters.h\"\n",
        "#define MAX_MASK_WIDTH 10\n",
        "\n",
        "__constant__ int M[MAX_MASK_WIDTH];\n",
        "\n",
        "__global__ void conv1Dcm(int *N,int *P,int Mask_width,int Width)\n",
        "{\n",
        "  int i=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  int p=0;\n",
        "  int NStartPoint=i-(Mask_width/2); \n",
        "  for(int j=0;j<Mask_width;j++)\n",
        "  {\n",
        "    if(NStartPoint+j>=0 && NStartPoint+j<Width)\n",
        "    {\n",
        "      p+=N[NStartPoint+j]*M[j];\n",
        "    }\n",
        "  }\n",
        "  P[i]=p;\n",
        "}\n",
        "\n",
        "__global__ void conv1Dsm(int *N,int *P,int Mask_width,int Width)\n",
        "{\n",
        "  extern __shared__ int temp_array[];\n",
        "  int id=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  temp_array[threadIdx.x]=N[id];\n",
        "  __syncthreads();\n",
        "  int p=0;\n",
        "  for(int i=0;i<Mask_width;i++)\n",
        "  {\n",
        "    if(threadIdx.x+i>=blockDim.x)\n",
        "    {\n",
        "      p+=N[id+i]*M[i];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "      p+=temp_array[threadIdx.x+i]*M[i];\n",
        "    }\n",
        "  }\n",
        "  P[id]=p;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int Width=10;\n",
        "    int Mask_width=3;\n",
        "\n",
        "    int h_N[]={0,1,2,3,4,5,6,7,8,9};\n",
        "    printf(\"\\n\\nInput array:\\n\");\n",
        "    for(int i=0;i<Width;i++)\n",
        "    {\n",
        "        printf(\"%d  \",h_N[i]);\n",
        "    }\n",
        "    int h_M[]={1,2,1};\n",
        "    printf(\"\\n\\nMask array:\\n\");\n",
        "    for(int i=0;i<Mask_width;i++)\n",
        "    {\n",
        "        printf(\"%d \",h_M[i]);\n",
        "    }\n",
        " \n",
        "    int h_P[Width];\n",
        "    int size=Width*sizeof(int);\n",
        "    int *d_N,*d_P;\n",
        "    float eTime1,eTime2;\n",
        "    cudaEvent_t begin,end,begin1,end1;\n",
        "\n",
        "    cudaMalloc((void**)&d_N,size);\n",
        "\t  cudaMalloc((void**)&d_P,size);\n",
        "\n",
        "\t  cudaMemcpy(d_N,h_N,size,cudaMemcpyHostToDevice);\n",
        "\t  cudaMemcpyToSymbol(M,h_M,Mask_width*sizeof(int));\n",
        "    cudaEventCreate(&begin);\n",
        "    cudaEventCreate(&end);\n",
        "    cudaEventCreate(&begin1);\n",
        "    cudaEventCreate(&end1);\n",
        "    cudaEventRecord(begin,0);\n",
        "\n",
        "    conv1Dcm<<<1,Width>>>(d_N,d_P,Mask_width,Width);\n",
        "    cudaEventRecord(end,0);\n",
        "    cudaEventSynchronize(end);\n",
        "    cudaEventElapsedTime(&eTime1,begin,end);\n",
        "\n",
        "    cudaMemcpy(h_P,d_P,size,cudaMemcpyDeviceToHost);\n",
        "    printf(\"\\n\\nOutput array from kernel 1:\\n\");\n",
        "    for(int i=0;i<Width;i++)\n",
        "    {\n",
        "        printf(\"%d   \",h_P[i]);\n",
        "    }\n",
        "    printf(\"\\nTime taken by kernel 1: %f\\n\",eTime1);\n",
        "    cudaEventRecord(begin1,0);\n",
        "\n",
        "    conv1Dsm<<<1,Width>>>(d_N,d_P,Mask_width,Width);\n",
        "    cudaEventRecord(end1,0);\n",
        "    cudaEventSynchronize(end1);\n",
        "    cudaEventElapsedTime(&eTime2,begin1,end1);\n",
        "\n",
        "    cudaMemcpy(h_P,d_P,size,cudaMemcpyDeviceToHost);\n",
        "    printf(\"\\n\\nOutput array from kernel 2:\\n\");\n",
        "    for(int i=0;i<Width;i++)\n",
        "    {\n",
        "        printf(\"%d   \",h_P[i]);\n",
        "    }\n",
        "    printf(\"\\nTime taken by kernel 2: %f\",eTime2);\n",
        "\n",
        "    cudaFree(d_N);\n",
        "\t  cudaFree(d_P);\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Input array:\n",
            "0  1  2  3  4  5  6  7  8  9  \n",
            "\n",
            "Mask array:\n",
            "1 2 1 \n",
            "\n",
            "Output array from kernel 1:\n",
            "1   4   8   12   16   20   24   28   32   26   \n",
            "Time taken by kernel 1: 0.021504\n",
            "\n",
            "\n",
            "Output array from kernel 2:\n",
            "1   4   8   12   16   20   24   28   32   26   \n",
            "Time taken by kernel 2: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWGYCAGzQLG0"
      },
      "source": [
        "#Question 2\n",
        "#####Write a program in CUDA to perform parallel Sparse Matrix - Vector Multiplication using compressed sparse row (CSR) storage format. Represent the input sparse matrix in CSR format in the host code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8DhrG9FSLxN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "223aed55-f788-452e-f765-21b8b7935365"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "#include\"cuda_runtime.h\"\n",
        "#include\"device_launch_parameters.h\"\n",
        "\n",
        "__global__ void Sparse_CSR(int num_rows,int *data,int *col_index,int *row_ptr,int *x,int *y)\n",
        "{\n",
        "  int row=threadIdx.x;\n",
        "  if(row<num_rows)\n",
        "  {\n",
        "    int dot=0;\n",
        "    int row_start=row_ptr[row];\n",
        "    int row_end=row_ptr[row+1];\n",
        "    for(int i=row_start;i<row_end;i++)\n",
        "    {\n",
        "      dot+= data[i]*x[col_index[i]];\n",
        "    }\n",
        "    y[row]=dot;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "    int n=3;\n",
        "    int y[n],row_ptr[n+1];\n",
        "    int ipmat[n][n]={{1,2,3},{4,5,6},{7,8,9}};\n",
        "    int x[]={1,2,3};\n",
        "    int nonzerocount=0;\n",
        "\n",
        "    printf(\"\\nInput Array:\\n\");\n",
        "    for(int i=0;i<n;i++)\n",
        "    {\n",
        "      row_ptr[i]=nonzerocount;\n",
        "      for(int j=0;j<n;j++)\n",
        "      {\n",
        "        if(ipmat[i][j]!=0)\n",
        "        {\n",
        "          nonzerocount++;\n",
        "        }\n",
        "        printf(\"%d\\t\",ipmat[i][j]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "    }\n",
        "    row_ptr[n]=nonzerocount;\n",
        "    int data[nonzerocount],col_index[nonzerocount];\n",
        "    int k=0;\n",
        "    //finding data and col_index array\n",
        "    for(int i=0;i<n;i++)\n",
        "    {\n",
        "      for(int j=0;j<n;j++)\n",
        "      {\n",
        "        if(ipmat[i][j]!=0)\n",
        "        {\n",
        "          data[k]=ipmat[i][j];\n",
        "          col_index[k++]=j;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    printf(\"\\n\\nValue Array:\\n\");\n",
        "    for(int i=0;i<nonzerocount;i++)\n",
        "    {\n",
        "      printf(\"%d  \",data[i]);\n",
        "    }\n",
        "    printf(\"\\n\\nColumn Index Array:\\n\");\n",
        "    for(int i=0;i<nonzerocount;i++)\n",
        "    {\n",
        "      printf(\"%d  \",col_index[i]);\n",
        "    }\n",
        "    printf(\"\\n\\nRow Pointer Array:\\n\");\n",
        "    for(int i=0;i<=n;i++)\n",
        "    {\n",
        "      printf(\"%d  \",row_ptr[i]);\n",
        "    }\n",
        "    printf(\"\\n\\nVector:\\n\");\n",
        "    for(int i=0;i<n;i++)\n",
        "    {\n",
        "      printf(\"%d  \",x[i]);\n",
        "    }\n",
        "    int *d_data,*d_col_index,*d_row_ptr,*d_x,*d_y;\n",
        "\n",
        "    cudaMalloc((void**)&d_data,nonzerocount*sizeof(int));\n",
        "    cudaMalloc((void**)&d_col_index,nonzerocount*sizeof(int));\n",
        "    cudaMalloc((void**)&d_row_ptr,(n+1)*sizeof(int));\n",
        "\t  cudaMalloc((void**)&d_x,n*sizeof(int));\n",
        "\t  cudaMalloc((void**)&d_y,n*sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_data,data,nonzerocount*sizeof(int),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_col_index,col_index,nonzerocount*sizeof(int),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_row_ptr,row_ptr,(n+1)*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\t  cudaMemcpy(d_x,x,n*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\n",
        "    Sparse_CSR<<<1,n>>>(n,d_data,d_col_index,d_row_ptr,d_x,d_y);\n",
        "\n",
        "    cudaMemcpy(y,d_y,n*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"\\n\\nResult:\\n\");\n",
        "    for(int i=0;i<n;i++)\n",
        "    {\n",
        "        printf(\"%d  \",y[i]);\n",
        "    }\n",
        "\n",
        "    cudaFree(d_data);\n",
        "    cudaFree(d_col_index);\n",
        "    cudaFree(d_row_ptr);\n",
        "\t  cudaFree(d_x);\n",
        "\t  cudaFree(d_y);\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Input Array:\n",
            "1\t2\t3\t\n",
            "4\t5\t6\t\n",
            "7\t8\t9\t\n",
            "\n",
            "\n",
            "Value Array:\n",
            "1  2  3  4  5  6  7  8  9  \n",
            "\n",
            "Column Index Array:\n",
            "0  1  2  0  1  2  0  1  2  \n",
            "\n",
            "Row Pointer Array:\n",
            "0  3  6  9  \n",
            "\n",
            "Vector:\n",
            "1  2  3  \n",
            "\n",
            "Result:\n",
            "14  32  50  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRpR8iGSQLhm"
      },
      "source": [
        "#Question 3\n",
        "#####Write a program in CUDA to perform matrix multiplication using 2D Grid and 2D Block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZuGZ_HASMww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "993698ca-f245-408c-b31d-81a32b906ef6"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "__global__ void mulmat(const int *a, const int *b, int *c, int m,int n,int o)\n",
        "{\n",
        "  int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "  int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  c[row * o + col] = 0;\n",
        "\n",
        "  for (int k = 0; k < n; k++) {\n",
        "    c[row * o + col] += a[row * n + k] * b[k * o + col];\n",
        "  }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  int size = sizeof(int);\n",
        "  int m=4,n=2,o=4;\n",
        "  int a[m][n]={{1,2},{3,4},{5,6},{7,8}};\n",
        "  int b[n][o]={{1,2,3,4},{1,2,3,4}};\n",
        "  int c[m][o];\n",
        " \n",
        "  int *d_a, *d_b, *d_c;\n",
        "  cudaMalloc(&d_a,m*n*size);\n",
        "  cudaMalloc(&d_b,n*o*size);\n",
        "  cudaMalloc(&d_c,m*o*size);\n",
        "\n",
        "  cudaMemcpy(d_a,a,m*n*size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b,b,n*o*size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  int thread=2;\n",
        "  dim3 threads(thread,thread);\n",
        "  dim3 blocks((m*o)/(4*thread),(m*o)/(4*thread));\n",
        "\n",
        "  mulmat<<<blocks, threads>>>(d_a, d_b, d_c,m,n,o);\n",
        "\n",
        "  cudaMemcpy(c, d_c,m*o*size, cudaMemcpyDeviceToHost);\n",
        " \n",
        "  printf(\"\\nMatrix 1:\\n\");\n",
        "  for(int i=0;i<m;i++)\n",
        "  {\n",
        "    for(int j=0;j<n;j++)\n",
        "    {\n",
        "      printf(\"%d\\t\",a[i][j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        " \n",
        "  printf(\"\\nMatrix 2:\\n\");\n",
        "  for(int i=0;i<n;i++)\n",
        "  {\n",
        "    for(int j=0;j<o;j++)\n",
        "    {\n",
        "      printf(\"%d\\t\",b[i][j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        " \n",
        "  printf(\"\\nFinal Matrix: \\n\");\n",
        "  for(int i=0;i<m;i++)\n",
        "  {\n",
        "    for(int j=0;j<o;j++)\n",
        "    {\n",
        "      printf(\"%d\\t\",c[i][j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  cudaFree(d_a);\n",
        "  cudaFree(d_b);\n",
        "  cudaFree(d_c);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Matrix 1:\n",
            "1\t2\t\n",
            "3\t4\t\n",
            "5\t6\t\n",
            "7\t8\t\n",
            "\n",
            "Matrix 2:\n",
            "1\t2\t3\t4\t\n",
            "1\t2\t3\t4\t\n",
            "\n",
            "Final Matrix: \n",
            "3\t6\t9\t12\t\n",
            "7\t14\t21\t28\t\n",
            "11\t22\t33\t44\t\n",
            "15\t30\t45\t60\t\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}